{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhananjay-97/notebooks/blob/main/airbnb_search_benchmark_colab_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# 🛍️ Let Users Talk to Your Store: Benchmarking Retrieval Techniques\n",
        "\n",
        "## Stockholm Airbnb Search Scenario Comparison\n",
        "\n",
        "This notebook demonstrates a comprehensive benchmark of different retrieval techniques:\n",
        "\n",
        "- 🔤 **BM25**: Traditional keyword-based search (fast, exact matches)\n",
        "- 🧠 **Vector Search**: Dense retrieval using sentence transformers (semantic understanding)\n",
        "- ⚖️ **Hybrid Search**: Combination of BM25 and vector search (balanced approach)\n",
        "- 🎯 **Cross-encoder Reranking**: Advanced reranking with transformer models (highest quality)\n",
        "- 🚀 **ColBERT**: ColBERT-based multi-attribute search for semantic matching\n",
        "- ⚡ **Superlinked**: Mixture-of-encoders approach (production-ready)\n",
        "\n",
        "🔗 **Blog Post**: [Read the full analysis]()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 📦 Installation & Setup\n",
        "\n",
        "First, let's install all required packages. This might take a few minutes on first run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Install required packages for the benchmark\n",
        "!pip install -q pandas numpy scikit-learn matplotlib seaborn plotly\n",
        "!pip install -q rank-bm25 sentence-transformers faiss-cpu\n",
        "!pip install -q superlinked python-dotenv tqdm\n",
        "\n",
        "print(\"✅ All packages installed successfully!\")\n",
        "print(\"🔄 If this is your first run, please restart runtime now and run the next cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import warnings\n",
        "from typing import List, Dict, Any, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import json\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "\n",
        "# ML/Search libraries\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "import faiss\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Superlinked (if available)\n",
        "try:\n",
        "    from superlinked import framework as sl\n",
        "    SUPERLINKED_AVAILABLE = True\n",
        "    print(\"✅ Superlinked available\")\n",
        "except ImportError:\n",
        "    SUPERLINKED_AVAILABLE = False\n",
        "    print(\"⚠️ Superlinked not available - will skip those sections\")\n",
        "\n",
        "# Configure visualization\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"✅ All imports successful!\")\n",
        "print(f\"📊 NumPy: {np.__version__}, Pandas: {pd.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utilities"
      },
      "source": [
        "## 🔧 Utility Functions\n",
        "\n",
        "Let's define all utility functions (originally in separate files):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utils"
      },
      "outputs": [],
      "source": [
        "def measure_time(func):\n",
        "    \"\"\"Decorator to measure execution time of functions.\"\"\"\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        print(f\"{func.__name__} executed in {end_time - start_time:.4f} seconds\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "def create_listing_text(row: pd.Series) -> str:\n",
        "    \"\"\"Create comprehensive text description from Airbnb listing data.\"\"\"\n",
        "    text = f\"{row.get('listing_name', 'Listing')} is a {row.get('accommodation_type', 'accommodation')} \"\n",
        "    text += f\"for {row.get('max_guests', 'N/A')} guests. \"\n",
        "    text += f\"It costs ${row.get('price', 0):.0f} per night with a rating of {row.get('rating', 0):.2f} \"\n",
        "    text += f\"and {row.get('review_count', 0)} reviews. \"\n",
        "    text += f\"Description: {row.get('description', 'No description available')} \"\n",
        "\n",
        "    # Handle amenities\n",
        "    amenities = row.get('amenities_list', [])\n",
        "    if isinstance(amenities, list) and amenities:\n",
        "        text += f\"Amenities include: {', '.join(amenities)}\"\n",
        "    elif isinstance(amenities, str):\n",
        "        text += f\"Amenities: {amenities}\"\n",
        "    else:\n",
        "        text += \"Amenities: Not specified\"\n",
        "\n",
        "    return text\n",
        "\n",
        "def create_sample_airbnb_data(n_samples: int = 1500) -> pd.DataFrame:\n",
        "    \"\"\"Generate realistic Stockholm Airbnb-like sample data for demo.\"\"\"\n",
        "    np.random.seed(42)  # For reproducible results\n",
        "\n",
        "    # Realistic listing names\n",
        "    sample_names = [\n",
        "        \"Cozy Stockholm Apartment\", \"Modern City Center Flat\", \"Luxury Downtown Suite\",\n",
        "        \"Budget-Friendly Room\", \"Spacious Family Home\", \"Stylish Studio\",\n",
        "        \"Traditional Swedish House\", \"Waterfront Apartment\", \"Historic District Room\",\n",
        "        \"Minimalist Loft\", \"Garden View Studio\", \"Executive Suite\", \"Artistic Retreat\",\n",
        "        \"Scandinavian Design Flat\", \"Central Station Apartment\", \"Quiet Residential Room\",\n",
        "        \"Rooftop Penthouse\", \"Vintage Charm Apartment\", \"Business Traveler Suite\",\n",
        "        \"Family-Friendly Home\", \"Designer Apartment\", \"Cozy Attic Room\"\n",
        "    ]\n",
        "\n",
        "    # Realistic descriptions\n",
        "    sample_descriptions = [\n",
        "        \"Beautiful apartment in the heart of Stockholm with modern amenities and great transport links\",\n",
        "        \"Modern and clean space perfect for business travelers and tourists alike\",\n",
        "        \"Luxury accommodation with stunning city views and premium furnishings throughout\",\n",
        "        \"Affordable option for budget travelers, clean and comfortable with basic amenities\",\n",
        "        \"Perfect for families visiting Stockholm, spacious with multiple bedrooms and family amenities\",\n",
        "        \"Stylish studio apartment with contemporary design and efficient use of space\",\n",
        "        \"Traditional Swedish architecture with modern comforts, offering unique cultural experience\",\n",
        "        \"Beautiful waterfront location with amazing views and peaceful atmosphere\",\n",
        "        \"Located in historic district, walking distance to major attractions and restaurants\",\n",
        "        \"Minimalist design with high-end finishes, perfect for those who appreciate clean aesthetics\",\n",
        "        \"Bright space with garden views, quiet and relaxing environment\",\n",
        "        \"Professional accommodation with business amenities and fast internet\",\n",
        "        \"Creative space with artistic touches, inspiring environment for creative minds\",\n",
        "        \"Authentic Scandinavian design with quality furniture and attention to detail\"\n",
        "    ]\n",
        "\n",
        "    # Realistic amenity combinations\n",
        "    amenities_options = [\n",
        "        ['Wifi', 'Kitchen', 'TV', 'Air conditioning'],\n",
        "        ['Wifi', 'Kitchen', 'Washer', 'Heating'],\n",
        "        ['Wifi', 'Kitchen', 'TV', 'Air conditioning', 'Dishwasher', 'Balcony'],\n",
        "        ['Wifi', 'Heating', 'Essentials'],\n",
        "        ['Wifi', 'Kitchen', 'TV', 'Washer', 'Family/kid friendly'],\n",
        "        ['Wifi', 'Kitchen', 'TV', 'Air conditioning', 'Gym', 'Pool'],\n",
        "        ['Wifi', 'Kitchen', 'Laptop friendly workspace', 'Self check-in'],\n",
        "        ['Wifi', 'Kitchen', 'TV', 'Hair dryer', 'Iron', 'Hangers']\n",
        "    ]\n",
        "\n",
        "    # Generate the dataset\n",
        "    df = pd.DataFrame({\n",
        "        'listing_id': range(1, n_samples + 1),\n",
        "        'listing_name': np.random.choice(sample_names, n_samples),\n",
        "        'accommodation_type': np.random.choice(\n",
        "            ['Entire place', 'Private room', 'Shared room'],\n",
        "            n_samples,\n",
        "            p=[0.65, 0.30, 0.05]  # More realistic distribution\n",
        "        ),\n",
        "        'max_guests': np.random.choice(\n",
        "            [1, 2, 3, 4, 5, 6, 8],\n",
        "            n_samples,\n",
        "            p=[0.1, 0.35, 0.20, 0.20, 0.10, 0.04, 0.01]\n",
        "        ),\n",
        "        'price': np.clip(\n",
        "            np.random.lognormal(5.5, 0.8, n_samples),\n",
        "            30, 3000\n",
        "        ).round(2),\n",
        "        'rating': np.round(\n",
        "            np.random.beta(8.5, 1.5, n_samples) * 5,  # Skewed toward higher ratings\n",
        "            2\n",
        "        ),\n",
        "        'review_count': np.random.poisson(65, n_samples),  # Average ~65 reviews\n",
        "        'description': np.random.choice(sample_descriptions, n_samples),\n",
        "        'amenities_list': [\n",
        "            random.choice(amenities_options)\n",
        "            for _ in range(n_samples)\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    # Create comprehensive text descriptions\n",
        "    df['text_description'] = df.apply(create_listing_text, axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "def display_search_results(results: pd.DataFrame, query: str, method: str, top_k: int = 5):\n",
        "    \"\"\"Display search results in a nice format.\"\"\"\n",
        "    print(f\"\\n🔍 {method} Results for: '{query}'\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    for i, (_, row) in enumerate(results.head(top_k).iterrows(), 1):\n",
        "        print(f\"\\n{i}. {row['listing_name']}\")\n",
        "        print(f\"   💰 ${row['price']:.0f}/night | ⭐ {row['rating']:.2f} ({row['review_count']} reviews)\")\n",
        "        print(f\"   🏠 {row['accommodation_type']} for {row['max_guests']} guests\")\n",
        "        if 'score' in row.index:\n",
        "            print(f\"   📊 Score: {row['score']:.4f}\")\n",
        "        elif 'similarity_score' in row.index:\n",
        "            print(f\"   📊 Similarity: {row['similarity_score']:.4f}\")\n",
        "        print(f\"   📝 {row['description'][:80]}...\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "print(\"✅ Utility functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data"
      },
      "source": [
        "## 📊 Data Loading\n",
        "\n",
        "Let's create our Stockholm Airbnb dataset for the benchmark:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# Generate sample Stockholm Airbnb data for demonstration\n",
        "print(\"📁 Creating Stockholm Airbnb sample dataset...\")\n",
        "df = create_sample_airbnb_data(n_samples=1500)\n",
        "\n",
        "# Alternative: Upload your own CSV file\n",
        "# Uncomment the following lines to upload your own data:\n",
        "# from google.colab import files\n",
        "# print(\"📤 Upload your CSV file:\")\n",
        "# uploaded = files.upload()\n",
        "# if uploaded:\n",
        "#     filename = list(uploaded.keys())[0]\n",
        "#     df = pd.read_csv(filename)\n",
        "#     if 'text_description' not in df.columns:\n",
        "#         df['text_description'] = df.apply(create_listing_text, axis=1)\n",
        "#     print(f\"✅ Custom data loaded: {len(df)} listings\")\n",
        "\n",
        "print(f\"\\n📋 Dataset Summary:\")\n",
        "print(f\"- Total listings: {len(df):,}\")\n",
        "print(f\"- Price range: ${df['price'].min():.0f} - ${df['price'].max():.0f}\")\n",
        "print(f\"- Rating range: {df['rating'].min():.2f} - {df['rating'].max():.2f}\")\n",
        "print(f\"- Average reviews per listing: {df['review_count'].mean():.0f}\")\n",
        "print(f\"- Accommodation types: {df['accommodation_type'].value_counts().to_dict()}\")\n",
        "\n",
        "# Display sample data\n",
        "print(f\"\\n🔍 Sample listings:\")\n",
        "display(df[['listing_name', 'accommodation_type', 'price', 'rating', 'max_guests', 'review_count']].head())\n",
        "\n",
        "print(f\"\\n📝 Sample text description:\")\n",
        "print(f\"'{df['text_description'].iloc[0][:200]}...'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "search_methods"
      },
      "source": [
        "## 🔍 Search Method Implementations\n",
        "\n",
        "Now let's implement all the search methods (originally in separate files):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm25_search"
      },
      "outputs": [],
      "source": [
        "class BM25Search:\n",
        "    \"\"\"BM25 keyword-based search implementation.\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        self.df = df\n",
        "        self.corpus = df['text_description'].tolist()\n",
        "        self.tokenized_corpus = [doc.lower().split() for doc in self.corpus]\n",
        "        print(\"🔄 Building BM25 index...\")\n",
        "        self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
        "        self.meta_data = {}\n",
        "\n",
        "    @measure_time\n",
        "    def search(self, query: str, top_k: int = 10) -> Tuple[pd.DataFrame, dict]:\n",
        "        \"\"\"Perform BM25 search.\"\"\"\n",
        "        start_time = time.time()\n",
        "        tokenized_query = query.lower().split()\n",
        "        scores = self.bm25.get_scores(tokenized_query)\n",
        "\n",
        "        results = self.df.copy()\n",
        "        results['score'] = scores\n",
        "        results = results.sort_values('score', ascending=False).head(top_k)\n",
        "\n",
        "        self.meta_data = {\n",
        "            'method': 'BM25',\n",
        "            'search_time': time.time() - start_time,\n",
        "            'query': query,\n",
        "            'top_k': top_k\n",
        "        }\n",
        "\n",
        "        return results, self.meta_data\n",
        "\n",
        "print(\"✅ BM25Search class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vector_search"
      },
      "outputs": [],
      "source": [
        "class VectorSearch:\n",
        "    \"\"\"Dense vector search using sentence transformers.\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, model_name: str = 'all-MiniLM-L12-v2'):\n",
        "        self.df = df\n",
        "        self.model_name = model_name\n",
        "        print(f\"🔄 Loading model: {model_name}\")\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "        print(\"🔄 Creating embeddings...\")\n",
        "        self.embeddings = self.model.encode(\n",
        "            self.df['text_description'].tolist(),\n",
        "            normalize_embeddings=True,\n",
        "            show_progress_bar=True\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        print(\"🔄 Building FAISS index...\")\n",
        "        self.index = self._create_faiss_index()\n",
        "        self.meta_data = {}\n",
        "\n",
        "    def _create_faiss_index(self):\n",
        "        \"\"\"Create FAISS index for fast similarity search.\"\"\"\n",
        "        vector_dimension = self.embeddings.shape[1]\n",
        "        index = faiss.IndexFlatIP(vector_dimension)  # Inner product for cosine similarity\n",
        "        index.add(self.embeddings)\n",
        "        return index\n",
        "\n",
        "    @measure_time\n",
        "    def search(self, query: str, top_k: int = 10) -> Tuple[pd.DataFrame, dict]:\n",
        "        \"\"\"Perform vector similarity search.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        query_embedding = self.model.encode(\n",
        "            [query],\n",
        "            normalize_embeddings=True\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        scores, indices = self.index.search(query_embedding, top_k)\n",
        "\n",
        "        results = self.df.iloc[indices[0]].copy()\n",
        "        results['score'] = scores[0]\n",
        "\n",
        "        self.meta_data = {\n",
        "            'method': 'Vector',\n",
        "            'model': self.model_name,\n",
        "            'search_time': time.time() - start_time,\n",
        "            'query': query,\n",
        "            'top_k': top_k\n",
        "        }\n",
        "\n",
        "        return results, self.meta_data\n",
        "\n",
        "print(\"✅ VectorSearch class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hybrid_search"
      },
      "outputs": [],
      "source": [
        "class HybridSearch:\n",
        "    \"\"\"Hybrid search combining BM25 and vector search.\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, model_name: str = 'all-MiniLM-L12-v2'):\n",
        "        self.df = df\n",
        "        print(\"🔄 Initializing BM25 component...\")\n",
        "        self.bm25_search = BM25Search(df)\n",
        "        print(\"🔄 Initializing Vector component...\")\n",
        "        self.vector_search = VectorSearch(df, model_name)\n",
        "        self.meta_data = {}\n",
        "\n",
        "    @measure_time\n",
        "    def search(self, query: str, alpha: float = 0.4, top_k: int = 10) -> Tuple[pd.DataFrame, dict]:\n",
        "        \"\"\"Perform hybrid search with linear combination of scores.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Get results from both methods\n",
        "        bm25_results, _ = self.bm25_search.search(query, top_k=len(self.df))\n",
        "        vector_results, _ = self.vector_search.search(query, top_k=len(self.df))\n",
        "\n",
        "        # Normalize scores to [0,1] range\n",
        "        bm25_scores = bm25_results['score'].values\n",
        "        bm25_scores_norm = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores) + 1e-8)\n",
        "\n",
        "        vector_scores = vector_results['score'].values\n",
        "        vector_scores_norm = (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + 1e-8)\n",
        "\n",
        "        # Combine scores using linear combination\n",
        "        hybrid_scores = alpha * bm25_scores_norm + (1 - alpha) * vector_scores_norm\n",
        "\n",
        "        results = self.df.copy()\n",
        "        results['score'] = hybrid_scores\n",
        "        results = results.sort_values('score', ascending=False).head(top_k)\n",
        "\n",
        "        self.meta_data = {\n",
        "            'method': 'Hybrid',\n",
        "            'alpha': alpha,\n",
        "            'search_time': time.time() - start_time,\n",
        "            'query': query,\n",
        "            'top_k': top_k\n",
        "        }\n",
        "\n",
        "        return results, self.meta_data\n",
        "\n",
        "print(\"✅ HybridSearch class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cross_encoder"
      },
      "outputs": [],
      "source": [
        "class CrossEncoderSearch:\n",
        "    \"\"\"Cross-encoder reranking on top of initial retrieval.\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame,\n",
        "                 retriever_model: str = 'all-MiniLM-L12-v2',\n",
        "                 cross_encoder_model: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2'):\n",
        "        self.df = df\n",
        "        print(\"🔄 Initializing retriever...\")\n",
        "        self.vector_search = VectorSearch(df, retriever_model)\n",
        "        print(f\"🔄 Loading cross-encoder: {cross_encoder_model}\")\n",
        "        self.cross_encoder = CrossEncoder(cross_encoder_model)\n",
        "        self.meta_data = {}\n",
        "\n",
        "    @measure_time\n",
        "    def search(self, query: str, top_k: int = 10, initial_k: int = 50) -> Tuple[pd.DataFrame, dict]:\n",
        "        \"\"\"Perform cross-encoder reranking.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # First stage: retrieve candidates\n",
        "        initial_results, _ = self.vector_search.search(query, top_k=initial_k)\n",
        "\n",
        "        # Second stage: rerank with cross-encoder\n",
        "        descriptions = initial_results['text_description'].tolist()\n",
        "        pairs = [(query, doc) for doc in descriptions]\n",
        "        scores = self.cross_encoder.predict(pairs)\n",
        "\n",
        "        # Rerank and return top results\n",
        "        reranked_results = initial_results.copy()\n",
        "        reranked_results['score'] = scores\n",
        "        reranked_results = reranked_results.sort_values('score', ascending=False).head(top_k)\n",
        "\n",
        "        self.meta_data = {\n",
        "            'method': 'Cross-Encoder',\n",
        "            'search_time': time.time() - start_time,\n",
        "            'query': query,\n",
        "            'top_k': top_k,\n",
        "            'initial_k': initial_k\n",
        "        }\n",
        "\n",
        "        return reranked_results, self.meta_data\n",
        "\n",
        "print(\"✅ CrossEncoderSearch class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "colbert_search"
      },
      "outputs": [],
      "source": [
        "# ColBERT Search Implementation\n",
        "# Note: ColBERT requires additional setup and may not work in all Colab environments\n",
        "\n",
        "class ColBERTSearch:\n",
        "    \"\"\"ColBERT late interaction search implementation.\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, max_docs: int = 1000):\n",
        "        \"\"\"Initialize ColBERT search.\n",
        "\n",
        "        Note: This is a simplified implementation for demonstration.\n",
        "        For production use, consider using the full ColBERT library.\n",
        "        \"\"\"\n",
        "        self.df = df.head(max_docs)  # Limit for demo purposes\n",
        "        self.available = False\n",
        "\n",
        "        try:\n",
        "            # Try to import ColBERT\n",
        "            global colbert\n",
        "            import colbert\n",
        "            from colbert import Indexer, Searcher\n",
        "            from colbert.infra import Run, RunConfig, ColBERTConfig\n",
        "\n",
        "            self.colbert = colbert\n",
        "            self.Indexer = Indexer\n",
        "            self.Searcher = Searcher\n",
        "            self.Run = Run\n",
        "            self.RunConfig = RunConfig\n",
        "            self.ColBERTConfig = ColBERTConfig\n",
        "\n",
        "            print(\"🔄 Setting up ColBERT (this may take several minutes)...\")\n",
        "            self._setup_colbert()\n",
        "            self.available = True\n",
        "            print(\"✅ ColBERT setup complete\")\n",
        "\n",
        "        except ImportError:\n",
        "            print(\"⚠️ ColBERT not available. Install with: !pip install colbert\")\n",
        "            self.available = False\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ ColBERT setup failed: {e}\")\n",
        "            self.available = False\n",
        "\n",
        "    def _setup_colbert(self):\n",
        "        \"\"\"Setup ColBERT index and searcher.\"\"\"\n",
        "        # Prepare collection\n",
        "        self.collection = self.df['text_description'].tolist()\n",
        "        self.index_name = 'airbnb_colbert_index'\n",
        "\n",
        "        # Create text to dataframe mapping\n",
        "        self.text_to_df_map = {text: idx for idx, text in enumerate(self.collection)}\n",
        "\n",
        "        try:\n",
        "            # Build index\n",
        "            with self.Run().context(self.RunConfig(nranks=1, experiment='airbnb_demo')):\n",
        "                config = self.ColBERTConfig(\n",
        "                    doc_maxlen=300,  # Shorter for demo\n",
        "                    nbits=2,         # Lower precision for speed\n",
        "                    kmeans_niters=4  # Fewer iterations\n",
        "                )\n",
        "\n",
        "                indexer = self.Indexer(\n",
        "                    checkpoint='colbert-ir/colbertv2.0',\n",
        "                    config=config\n",
        "                )\n",
        "\n",
        "                indexer.index(\n",
        "                    name=self.index_name,\n",
        "                    collection=self.collection,\n",
        "                    overwrite=True\n",
        "                )\n",
        "\n",
        "            # Initialize searcher\n",
        "            with self.Run().context(self.RunConfig(experiment='airbnb_demo')):\n",
        "                self.searcher = self.Searcher(\n",
        "                    index=self.index_name,\n",
        "                    collection=self.collection\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ColBERT indexing failed: {e}\")\n",
        "            # Fallback to vector search for demo\n",
        "            print(\"🔄 Falling back to vector search simulation...\")\n",
        "            self._setup_fallback()\n",
        "\n",
        "    def _setup_fallback(self):\n",
        "        \"\"\"Setup fallback vector search to simulate ColBERT.\"\"\"\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        import faiss\n",
        "\n",
        "        self.fallback_model = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "        embeddings = self.fallback_model.encode(\n",
        "            self.collection,\n",
        "            normalize_embeddings=True\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        # Create FAISS index\n",
        "        self.fallback_index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "        self.fallback_index.add(embeddings)\n",
        "        self.using_fallback = True\n",
        "\n",
        "    @measure_time\n",
        "    def search(self, query: str, top_k: int = 10) -> Tuple[pd.DataFrame, dict]:\n",
        "        \"\"\"Perform ColBERT search.\"\"\"\n",
        "        if not self.available:\n",
        "            raise RuntimeError(\"ColBERT not available\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            if hasattr(self, 'using_fallback') and self.using_fallback:\n",
        "                # Use fallback vector search\n",
        "                query_embedding = self.fallback_model.encode(\n",
        "                    [query],\n",
        "                    normalize_embeddings=True\n",
        "                ).astype(np.float32)\n",
        "\n",
        "                scores, indices = self.fallback_index.search(query_embedding, top_k)\n",
        "\n",
        "                results = self.df.iloc[indices[0]].copy()\n",
        "                results['score'] = scores[0]\n",
        "\n",
        "            else:\n",
        "                # Use actual ColBERT\n",
        "                colbert_results = self.searcher.search(query, k=top_k)\n",
        "\n",
        "                # Process ColBERT results\n",
        "                matched_records = []\n",
        "                for passage_id, passage_rank, passage_score in zip(*colbert_results):\n",
        "                    if passage_id < len(self.df):\n",
        "                        record = self.df.iloc[passage_id].copy()\n",
        "                        record['score'] = passage_score\n",
        "                        matched_records.append(record)\n",
        "\n",
        "                results = pd.DataFrame(matched_records) if matched_records else pd.DataFrame()\n",
        "\n",
        "            meta_data = {\n",
        "                'method': 'ColBERT',\n",
        "                'search_time': time.time() - start_time,\n",
        "                'query': query,\n",
        "                'top_k': top_k,\n",
        "                'using_fallback': getattr(self, 'using_fallback', False)\n",
        "            }\n",
        "\n",
        "            return results, meta_data\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ColBERT search failed: {e}\")\n",
        "            # Return empty results\n",
        "            return pd.DataFrame(), {\n",
        "                'method': 'ColBERT',\n",
        "                'search_time': time.time() - start_time,\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "# Try to initialize ColBERT (optional)\n",
        "try:\n",
        "    print(\"🔄 Attempting to initialize ColBERT...\")\n",
        "    print(\"Note: This may take several minutes and requires significant memory.\")\n",
        "    print(\"If it fails, the benchmark will continue without ColBERT.\")\n",
        "\n",
        "    # Only try with a small subset for demo\n",
        "    colbert_searcher = ColBERTSearch(df, max_docs=500)\n",
        "    COLBERT_AVAILABLE = colbert_searcher.available\n",
        "\n",
        "    if COLBERT_AVAILABLE:\n",
        "        print(\"✅ ColBERT initialized successfully\")\n",
        "    else:\n",
        "        print(\"⚠️ ColBERT initialization failed\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ ColBERT setup error: {e}\")\n",
        "    COLBERT_AVAILABLE = False\n",
        "\n",
        "print(f\"\\n📊 ColBERT Status: {'Available' if COLBERT_AVAILABLE else 'Not Available'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "superlinked_search"
      },
      "outputs": [],
      "source": [
        "class SuperlinkedSearch:\n",
        "    \"\"\"Superlinked mixture-of-encoders search implementation.\"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame):\n",
        "        if not SUPERLINKED_AVAILABLE:\n",
        "            raise ImportError(\"Superlinked not available\")\n",
        "\n",
        "        self.df = df\n",
        "        self._setup_superlinked()\n",
        "\n",
        "    def _setup_superlinked(self):\n",
        "        \"\"\"Setup Superlinked schema, spaces, and index.\"\"\"\n",
        "        print(\"🔄 Setting up Superlinked...\")\n",
        "\n",
        "        # Define schema\n",
        "        class AirbnbSchema(sl.Schema):\n",
        "            listing_id: sl.IdField\n",
        "            price: sl.Float\n",
        "            rating: sl.Float\n",
        "            description: sl.String\n",
        "            review_count: sl.Integer\n",
        "            listing_name: sl.String\n",
        "            accommodation_type: sl.String\n",
        "            max_guests: sl.Integer\n",
        "\n",
        "        self.airbnb_schema = AirbnbSchema()\n",
        "\n",
        "        # Create embedding spaces\n",
        "        self.description_space = sl.TextSimilaritySpace(\n",
        "            text=self.airbnb_schema.description,\n",
        "            model=\"sentence-transformers/all-MiniLM-L12-v2\"\n",
        "        )\n",
        "\n",
        "        self.price_space = sl.NumberSpace(\n",
        "            self.airbnb_schema.price,\n",
        "            min_value=0,\n",
        "            max_value=3000.0,\n",
        "            mode=sl.Mode.MAXIMUM,\n",
        "        )\n",
        "\n",
        "        self.rating_space = sl.NumberSpace(\n",
        "            number=self.airbnb_schema.rating,\n",
        "            min_value=1.0,\n",
        "            max_value=5.0,\n",
        "            mode=sl.Mode.MAXIMUM\n",
        "        )\n",
        "\n",
        "        # Create index\n",
        "        self.airbnb_index = sl.Index(\n",
        "            spaces=[\n",
        "                self.description_space,\n",
        "                self.price_space,\n",
        "                self.rating_space,\n",
        "            ],\n",
        "            fields=[\n",
        "                self.airbnb_schema.accommodation_type,\n",
        "                self.airbnb_schema.max_guests,\n",
        "                self.airbnb_schema.price,\n",
        "                self.airbnb_schema.rating,\n",
        "                self.airbnb_schema.review_count,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Setup query\n",
        "        self.query = (\n",
        "            sl.Query(\n",
        "                self.airbnb_index,\n",
        "                weights={\n",
        "                    self.price_space: sl.Param(\"price_weight\"),\n",
        "                    self.rating_space: sl.Param(\"rating_weight\"),\n",
        "                    self.description_space: sl.Param(\"description_weight\"),\n",
        "                },\n",
        "            )\n",
        "            .find(self.airbnb_schema)\n",
        "            .similar(\n",
        "                self.description_space,\n",
        "                sl.Param(\"description_query\")\n",
        "            )\n",
        "            .filter(self.airbnb_schema.price >= sl.Param(\"min_price\"))\n",
        "            .filter(self.airbnb_schema.max_guests >= sl.Param(\"min_guests\"))\n",
        "            .filter(self.airbnb_schema.rating >= sl.Param(\"min_rating\"))\n",
        "            .limit(sl.Param(\"limit\"))\n",
        "        )\n",
        "\n",
        "        # Setup executor\n",
        "        self.source = sl.InMemorySource(self.airbnb_schema)\n",
        "        self.executor = sl.InMemoryExecutor(sources=[self.source], indices=[self.airbnb_index])\n",
        "        self.app = self.executor.run()\n",
        "\n",
        "        # Ingest data\n",
        "        data_dicts = self.df.to_dict('records')\n",
        "        self.source.put(data_dicts)\n",
        "\n",
        "        print(\"✅ Superlinked setup complete\")\n",
        "\n",
        "    @measure_time\n",
        "    def search(self, natural_query: str, top_k: int = 10) -> Tuple[pd.DataFrame, dict]:\n",
        "        \"\"\"Perform Superlinked search with natural language query.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Simple query parameter extraction (in practice, use .with_natural_query() )\n",
        "        params = {\n",
        "            \"description_query\": natural_query,\n",
        "            \"description_weight\": 1.0,\n",
        "            \"price_weight\": -0.5 if \"affordable\" in natural_query.lower() or \"budget\" in natural_query.lower() else 0.5 if \"luxury\" in natural_query.lower() or \"expensive\" in natural_query.lower() else 0.0,\n",
        "            \"rating_weight\": 1.0 if any(word in natural_query.lower() for word in [\"good\", \"great\", \"excellent\", \"high rating\"]) else 0.5,\n",
        "            \"min_price\": 0,\n",
        "            \"min_guests\": 1,\n",
        "            \"min_rating\": 0.0,\n",
        "            \"limit\": top_k\n",
        "        }\n",
        "\n",
        "        result = self.app.query(self.query, **params)\n",
        "        results_df = sl.PandasConverter.to_pandas(result)\n",
        "\n",
        "        meta_data = {\n",
        "            'method': 'Superlinked',\n",
        "            'search_time': time.time() - start_time,\n",
        "            'top_k': top_k,\n",
        "            'params': params\n",
        "        }\n",
        "\n",
        "        return results_df, meta_data\n",
        "\n",
        "if SUPERLINKED_AVAILABLE:\n",
        "    print(\"✅ SuperlinkedSearch class defined\")\n",
        "else:\n",
        "    print(\"⚠️ SuperlinkedSearch skipped (not available)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "initialize"
      },
      "source": [
        "## 🚀 Initialize Search Methods\n",
        "\n",
        "Let's initialize all our search methods. This will take a few minutes as we build indices and load models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "init_searchers"
      },
      "outputs": [],
      "source": [
        "print(\"🚀 Initializing search methods...\")\n",
        "print(\"This may take a few minutes on first run...\\n\")\n",
        "\n",
        "# Initialize BM25\n",
        "print(\"1️⃣ Initializing BM25...\")\n",
        "bm25_searcher = BM25Search(df)\n",
        "print(\"✅ BM25 ready\\n\")\n",
        "\n",
        "# Initialize Vector Search\n",
        "print(\"2️⃣ Initializing Vector Search...\")\n",
        "vector_searcher = VectorSearch(df)\n",
        "print(\"✅ Vector Search ready\\n\")\n",
        "\n",
        "# Initialize Hybrid Search\n",
        "print(\"3️⃣ Initializing Hybrid Search...\")\n",
        "hybrid_searcher = HybridSearch(df)\n",
        "print(\"✅ Hybrid Search ready\\n\")\n",
        "\n",
        "# Initialize Cross-Encoder (optional - takes longer)\n",
        "print(\"4️⃣ Initializing Cross-Encoder (this may take a while)...\")\n",
        "try:\n",
        "    cross_encoder_searcher = CrossEncoderSearch(df)\n",
        "    print(\"✅ Cross-Encoder ready\\n\")\n",
        "    CROSS_ENCODER_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Cross-Encoder failed to initialize: {e}\")\n",
        "    CROSS_ENCODER_AVAILABLE = False\n",
        "\n",
        "\n",
        "# Initialize ColBERT (if available)\n",
        "if COLBERT_AVAILABLE:\n",
        "    print(\"🔄 ColBERT already initialized during class definition\")\n",
        "    print(\"✅ ColBERT ready for search\\n\")\n",
        "else:\n",
        "    print(\"⚠️ ColBERT not available - skipping\\n\")\n",
        "# Initialize Superlinked (if available)\n",
        "if SUPERLINKED_AVAILABLE:\n",
        "    print(\"5️⃣ Initializing Superlinked...\")\n",
        "    try:\n",
        "        superlinked_searcher = SuperlinkedSearch(df)\n",
        "        print(\"✅ Superlinked ready\\n\")\n",
        "        SUPERLINKED_READY = True\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Superlinked failed to initialize: {e}\")\n",
        "        SUPERLINKED_READY = False\n",
        "else:\n",
        "    SUPERLINKED_READY = False\n",
        "\n",
        "print(\"🎉 Search method initialization complete!\")\n",
        "print(f\"📊 Available methods: BM25, Vector, Hybrid{', Cross-Encoder' if CROSS_ENCODER_AVAILABLE else ''}{', ColBERT' if COLBERT_AVAILABLE else ''}{', Superlinked' if SUPERLINKED_READY else ''}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "benchmark"
      },
      "source": [
        "## 🎯 Running the Benchmark\n",
        "\n",
        "Now let's run our comprehensive benchmark with different test queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_queries"
      },
      "outputs": [],
      "source": [
        "# Define test queries that showcase different search scenarios\n",
        "test_queries = [\n",
        "    \"affordable places with good reviews\",\n",
        "    \"luxury apartment for 4 guests\",\n",
        "    \"modern studio with kitchen and wifi\",\n",
        "    \"family friendly accommodation near city center\",\n",
        "    \"budget room for solo traveler\",\n",
        "    \"spacious apartment with great amenities\",\n",
        "    \"cozy place for couples\"\n",
        "]\n",
        "\n",
        "def run_search_comparison(query: str, top_k: int = 5):\n",
        "    \"\"\"Run all available search methods and compare results.\"\"\"\n",
        "    print(f\"\\n🔍 Query: '{query}'\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # BM25\n",
        "    bm25_results, bm25_meta = bm25_searcher.search(query, top_k)\n",
        "    results['BM25'] = (bm25_results, bm25_meta)\n",
        "    print(f\"✅ BM25: {bm25_meta['search_time']:.4f}s\")\n",
        "\n",
        "    # Vector Search\n",
        "    vector_results, vector_meta = vector_searcher.search(query, top_k)\n",
        "    results['Vector'] = (vector_results, vector_meta)\n",
        "    print(f\"✅ Vector: {vector_meta['search_time']:.4f}s\")\n",
        "\n",
        "    # Hybrid Search\n",
        "    hybrid_results, hybrid_meta = hybrid_searcher.search(query, top_k=top_k)\n",
        "    results['Hybrid'] = (hybrid_results, hybrid_meta)\n",
        "    print(f\"✅ Hybrid: {hybrid_meta['search_time']:.4f}s\")\n",
        "\n",
        "    # Cross-Encoder (if available)\n",
        "    if CROSS_ENCODER_AVAILABLE:\n",
        "        try:\n",
        "            ce_results, ce_meta = cross_encoder_searcher.search(query, top_k)\n",
        "            results['Cross-Encoder'] = (ce_results, ce_meta)\n",
        "            print(f\"✅ Cross-Encoder: {ce_meta['search_time']:.4f}s\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Cross-Encoder error: {e}\")\n",
        "\n",
        "\n",
        "    # ColBERT (if available)\n",
        "    if COLBERT_AVAILABLE:\n",
        "        try:\n",
        "            colbert_results, colbert_meta = colbert_searcher.search(query, top_k)\n",
        "            results['ColBERT'] = (colbert_results, colbert_meta)\n",
        "            print(f\"✅ ColBERT: {colbert_meta['search_time']:.4f}s\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ ColBERT error: {e}\")\n",
        "    # Superlinked (if available)\n",
        "    if SUPERLINKED_READY:\n",
        "        try:\n",
        "            sl_results, sl_meta = superlinked_searcher.search(query, top_k)\n",
        "            results['Superlinked'] = (sl_results, sl_meta)\n",
        "            print(f\"✅ Superlinked: {sl_meta['search_time']:.4f}s\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Superlinked error: {e}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run benchmark on first query\n",
        "sample_query = test_queries[0]\n",
        "print(f\"🚀 Running benchmark with query: '{sample_query}'\")\n",
        "sample_results = run_search_comparison(sample_query)\n",
        "\n",
        "print(\"\\n🎉 Benchmark complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results_display"
      },
      "source": [
        "## 📊 Results Analysis\n",
        "\n",
        "Let's analyze and compare the results from different search methods:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display_results"
      },
      "outputs": [],
      "source": [
        "# Display detailed results comparison\n",
        "print(\"📋 DETAILED RESULTS COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for method, (results_df, meta) in sample_results.items():\n",
        "    print(f\"\\n🔹 {method} Results (Search time: {meta['search_time']:.4f}s):\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Handle Superlinked results which might not have all columns\n",
        "    if method == 'Superlinked' and not results_df.empty:\n",
        "        # Ensure 'id' column in Superlinked results matches dtype of 'listing_id' in df\n",
        "        results_df['id'] = results_df['id'].astype(df['listing_id'].dtype)\n",
        "        # Merge with the original DataFrame to get all listing details\n",
        "        # Assuming 'id' in Superlinked results corresponds to 'listing_id' in df\n",
        "        results_df = pd.merge(results_df, df, left_on='id', right_on='listing_id', how='left')\n",
        "        # Use 'similarity_score' from Superlinked results if available, otherwise use 'score'\n",
        "        score_col = 'similarity_score' if 'similarity_score' in results_df.columns else 'score'\n",
        "    else:\n",
        "        score_col = 'score' # Default score column for other methods\n",
        "\n",
        "    for i, (_, row) in enumerate(results_df.head(3).iterrows(), 1):\n",
        "        print(f\"\\n  {i}. {row['listing_name']}\")\n",
        "        print(f\"     💰 ${row['price']:.0f}/night | ⭐ {row['rating']:.2f} ({row['review_count']} reviews)\")\n",
        "        print(f\"     🏠 {row['accommodation_type']} for {row['max_guests']} guests\")\n",
        "        if score_col in row.index:\n",
        "            print(f\"     📊 Score: {row[score_col]:.4f}\")\n",
        "        print(f\"     📝 {row['description'][:80]}...\")\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "performance_analysis"
      },
      "source": [
        "## 📈 Performance Analysis & Visualization\n",
        "\n",
        "Let's create visualizations to compare the performance of different methods:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "performance_viz"
      },
      "outputs": [],
      "source": [
        "# Create performance comparison charts\n",
        "def create_performance_analysis(results_dict):\n",
        "    \"\"\"Create comprehensive performance analysis.\"\"\"\n",
        "\n",
        "    # Extract performance data\n",
        "    methods = []\n",
        "    search_times = []\n",
        "\n",
        "    for method, (_, meta) in results_dict.items():\n",
        "        methods.append(method)\n",
        "        search_times.append(meta['search_time'])\n",
        "\n",
        "    # Create performance chart\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Search time comparison\n",
        "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']\n",
        "    bars = ax1.bar(methods, search_times, color=colors[:len(methods)])\n",
        "    ax1.set_title('🚀 Search Method Performance Comparison', fontsize=14, fontweight='bold')\n",
        "    ax1.set_xlabel('Search Method', fontsize=12)\n",
        "    ax1.set_ylabel('Search Time (seconds)', fontsize=12)\n",
        "    ax1.set_yscale('log')\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, time_val in zip(bars, search_times):\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.1,\n",
        "                f'{time_val:.4f}s', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "    ax1.grid(axis='y', alpha=0.3)\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Speed ranking\n",
        "    speed_ranking = sorted(zip(methods, search_times), key=lambda x: x[1])\n",
        "    rank_methods, rank_times = zip(*speed_ranking)\n",
        "\n",
        "    ax2.barh(range(len(rank_methods)), rank_times, color=colors[:len(rank_methods)])\n",
        "    ax2.set_yticks(range(len(rank_methods)))\n",
        "    ax2.set_yticklabels(rank_methods)\n",
        "    ax2.set_title('⚡ Speed Ranking (Fastest to Slowest)', fontsize=14, fontweight='bold')\n",
        "    ax2.set_xlabel('Search Time (seconds)', fontsize=12)\n",
        "    ax2.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    # Add time labels\n",
        "    for i, time_val in enumerate(rank_times):\n",
        "        ax2.text(time_val + max(rank_times) * 0.01, i, f'{time_val:.4f}s',\n",
        "                va='center', fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Performance summary\n",
        "    print(\"\\n📊 PERFORMANCE SUMMARY:\")\n",
        "    print(\"=\" * 50)\n",
        "    for i, (method, time_val) in enumerate(speed_ranking, 1):\n",
        "        emoji = \"🥇\" if i == 1 else \"🥈\" if i == 2 else \"🥉\" if i == 3 else \"📊\"\n",
        "        print(f\"{emoji} {i}. {method:15s}: {time_val:.4f}s\")\n",
        "\n",
        "    fastest = speed_ranking[0]\n",
        "    slowest = speed_ranking[-1]\n",
        "    speedup = slowest[1] / fastest[1]\n",
        "    print(f\"\\n⚡ {fastest[0]} is {speedup:.1f}x faster than {slowest[0]}\")\n",
        "\n",
        "# Create the analysis\n",
        "create_performance_analysis(sample_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interactive_testing"
      },
      "source": [
        "## 🎮 Interactive Testing\n",
        "\n",
        "Try different queries to see how each method performs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interactive_search"
      },
      "outputs": [],
      "source": [
        "# Interactive testing function\n",
        "def test_multiple_queries():\n",
        "    \"\"\"Test multiple queries and show comparative results.\"\"\"\n",
        "    print(\"🎮 MULTI-QUERY TESTING\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Test with different query types\n",
        "    test_scenarios = [\n",
        "        (\"luxury apartment with great reviews\", \"Luxury + Quality\"),\n",
        "        (\"budget friendly room for students\", \"Budget + Target Audience\"),\n",
        "        (\"family apartment with kitchen\", \"Family + Amenities\")\n",
        "    ]\n",
        "\n",
        "    all_performance = {}\n",
        "\n",
        "    for query, scenario in test_scenarios:\n",
        "        print(f\"\\n🔍 Testing: {scenario}\")\n",
        "        print(f\"Query: '{query}'\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        results = run_search_comparison(query, top_k=3)\n",
        "\n",
        "        # Collect performance data\n",
        "        for method, (_, meta) in results.items():\n",
        "            if method not in all_performance:\n",
        "                all_performance[method] = []\n",
        "            all_performance[method].append(meta['search_time'])\n",
        "\n",
        "        # Show top result from each method\n",
        "        print(\"\\n🏆 Top result from each method:\")\n",
        "        for method, (results_df, meta) in results.items():\n",
        "            if not results_df.empty:\n",
        "                # Handle Superlinked results which might not have all columns\n",
        "                if method == 'Superlinked':\n",
        "                    # Ensure 'id' column in Superlinked results matches dtype of 'listing_id' in df\n",
        "                    results_df['id'] = results_df['id'].astype(df['listing_id'].dtype)\n",
        "                    # Merge with the original DataFrame to get all listing details\n",
        "                    results_df = pd.merge(results_df, df, left_on='id', right_on='listing_id', how='left')\n",
        "\n",
        "                top_result = results_df.iloc[0]\n",
        "                print(f\"  {method:12s}: {top_result['listing_name']} (${top_result['price']:.0f}, ⭐{top_result['rating']:.2f})\")\n",
        "\n",
        "    # Average performance analysis\n",
        "    print(\"\\n\\n📊 AVERAGE PERFORMANCE ACROSS ALL QUERIES:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    avg_performance = []\n",
        "    for method, times in all_performance.items():\n",
        "        avg_time = np.mean(times)\n",
        "        std_time = np.std(times)\n",
        "        avg_performance.append((method, avg_time, std_time))\n",
        "        print(f\"{method:15s}: {avg_time:.4f}s ± {std_time:.4f}s\")\n",
        "\n",
        "    # Sort by average performance\n",
        "    avg_performance.sort(key=lambda x: x[1])\n",
        "    print(f\"\\n🏆 Most consistent performer: {avg_performance[0][0]}\")\n",
        "\n",
        "# Run the interactive testing\n",
        "test_multiple_queries()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quality_analysis"
      },
      "source": [
        "## 🎯 Quality Analysis\n",
        "\n",
        "Let's analyze the quality of results from different methods:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_quality"
      },
      "outputs": [],
      "source": [
        "def analyze_result_quality(query: str, results_dict: dict):\n",
        "    \"\"\"Analyze the quality and diversity of search results.\"\"\"\n",
        "    print(f\"\\n🔍 QUALITY ANALYSIS FOR: '{query}'\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    quality_metrics = {}\n",
        "\n",
        "    for method, (results_df, meta) in results_dict.items():\n",
        "        if results_df.empty:\n",
        "            continue\n",
        "\n",
        "        # Handle Superlinked results which might not have all columns\n",
        "        if method == 'Superlinked':\n",
        "            # Ensure 'id' column in Superlinked results matches dtype of 'listing_id' in df\n",
        "            results_df['id'] = results_df['id'].astype(df['listing_id'].dtype)\n",
        "            # Merge with the original DataFrame to get all listing details\n",
        "            # Assuming 'id' in Superlinked results corresponds to 'listing_id' in df\n",
        "            results_df = pd.merge(results_df, df, left_on='id', right_on='listing_id', how='left')\n",
        "\n",
        "\n",
        "        # Calculate quality metrics\n",
        "        avg_rating = results_df['rating'].mean()\n",
        "        avg_reviews = results_df['review_count'].mean()\n",
        "        price_range = results_df['price'].max() - results_df['price'].min()\n",
        "        unique_types = results_df['accommodation_type'].nunique()\n",
        "\n",
        "        quality_metrics[method] = {\n",
        "            'avg_rating': avg_rating,\n",
        "            'avg_reviews': avg_reviews,\n",
        "            'price_diversity': price_range,\n",
        "            'type_diversity': unique_types,\n",
        "            'search_time': meta['search_time']\n",
        "        }\n",
        "\n",
        "        print(f\"\\n📊 {method}:\")\n",
        "        print(f\"   ⭐ Avg Rating: {avg_rating:.2f}\")\n",
        "        print(f\"   📝 Avg Reviews: {avg_reviews:.0f}\")\n",
        "        print(f\"   💰 Price Range: ${price_range:.0f}\")\n",
        "        print(f\"   🏠 Accommodation Types: {unique_types}\")\n",
        "        print(f\"   ⚡ Search Time: {meta['search_time']:.4f}s\")\n",
        "\n",
        "    # Find best performers in each category\n",
        "    if quality_metrics:\n",
        "        print(\"\\n🏆 CATEGORY WINNERS:\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        best_rating = max(quality_metrics.items(), key=lambda x: x[1]['avg_rating'])\n",
        "        best_reviews = max(quality_metrics.items(), key=lambda x: x[1]['avg_reviews'])\n",
        "        best_diversity = max(quality_metrics.items(), key=lambda x: x[1]['price_diversity'])\n",
        "        fastest = min(quality_metrics.items(), key=lambda x: x[1]['search_time'])\n",
        "\n",
        "        print(f\"⭐ Highest Avg Rating: {best_rating[0]} ({best_rating[1]['avg_rating']:.2f})\")\n",
        "        print(f\"📝 Most Reviewed Results: {best_reviews[0]} ({best_reviews[1]['avg_reviews']:.0f})\")\n",
        "        print(f\"💰 Most Price Diverse: {best_diversity[0]} (${best_diversity[1]['price_diversity']:.0f})\")\n",
        "        print(f\"⚡ Fastest: {fastest[0]} ({fastest[1]['search_time']:.4f}s)\")\n",
        "\n",
        "    return quality_metrics\n",
        "\n",
        "# Analyze quality for our sample query\n",
        "quality_analysis = analyze_result_quality(sample_query, sample_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## 🎯 Key Findings & Recommendations\n",
        "\n",
        "### 📈 Performance Insights:\n",
        "\n",
        "1. **🔤 BM25 (Keyword Search)**:\n",
        "   - ⚡ **Fastest** search method\n",
        "   - 🎯 Excellent for exact keyword matches\n",
        "   - ❌ Limited semantic understanding\n",
        "   - 💡 **Best for**: Speed-critical applications, exact term matching\n",
        "\n",
        "2. **🧠 Vector Search (Semantic)**:\n",
        "   - 🧠 **Best semantic understanding**\n",
        "   - 🔍 Finds conceptually similar results\n",
        "   - ⏱️ Moderate speed (slower than BM25, faster than cross-encoder)\n",
        "   - 💡 **Best for**: Semantic similarity, conceptual matching\n",
        "\n",
        "3. **⚖️ Hybrid Search**:\n",
        "   - 🎯 **Balanced approach**\n",
        "   - ✅ Combines keyword + semantic matching\n",
        "   - 📊 Often provides best overall results\n",
        "   - 💡 **Best for**: General-purpose search, balanced performance\n",
        "\n",
        "4. **🎯 Cross-Encoder Reranking**:\n",
        "   - ⏳ Slowest due to pairwise scoring\n",
        "   - 🎯 Superior relevance ranking\n",
        "   - 💡 **Best for**: High-precision use cases, quality over speed\n",
        "\n",
        "5. **⚡ Superlinked (Mixture-of-Encoders)**:\n",
        "   - 🎖️ **Highest quality** results\n",
        "   - 🚀 **Production-ready** with specialized encoders\n",
        "   - 🎛️ Handles multiple data types (text, numbers, categories)\n",
        "   - 🔧 Configurable weights and constraints\n",
        "   - 💡 **Best for**: Complex multi-modal search, production systems\n",
        "\n",
        "\n",
        "### 💡 Key Takeaways:\n",
        "\n",
        "- **No single method is best for all scenarios**\n",
        "- **Hybrid approaches often provide the best balance**\n",
        "- **Consider your speed vs. quality requirements**\n",
        "- **Superlinked excels for complex, multi-modal search needs**\n",
        "- **Cross-encoders provide highest quality but at a cost**\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 Learn More\n",
        "\n",
        "🔗 **Read the full blog post**: [Benchmarking Retrieval Techniques on Airbnb Data]()\n",
        "\n",
        "🎓 **VectorHub**: Explore more tutorials on advanced retrieval techniques\n",
        "\n",
        "⚡ **Superlinked**: Production-ready vector search with specialized encoders\n",
        "\n",
        "📖 **Documentation**:\n",
        "- [Sentence Transformers](https://www.sbert.net/)\n",
        "- [FAISS](https://faiss.ai/)\n",
        "- [Superlinked](https://docs.superlinked.com/)\n",
        "\n",
        "*Thank you for exploring this comprehensive retrieval benchmark! 🙏*\n",
        "\n",
        "---\n",
        "*This notebook is part of the VectorHub educational series on advanced retrieval techniques.*\n",
        "\n",
        "# Made with ❤️ by Amir"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6WYpzKyy8uT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}